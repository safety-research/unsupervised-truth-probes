{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Ground truth labels len: 200, true labels: 127, false labels: 73\n",
      "Split: 100 train, 100 test examples\n",
      "Num test labels: 100, true labels: 47, false labels: 53\n",
      "Some results missing, computing activations...\n",
      "Loading model: meta-llama/Llama-3.1-70B\n",
      "Detected positive token: 'True' (ID: 2575)\n",
      "Detected negative token: 'False' (ID: 4139)\n",
      "Computing activations for all prompts...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79bbb3ac16d496e81a280bbe967a6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1bc7cca7e24605b40f1a7e03c4e759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train labels: 100, true labels: 63, false labels: 37\n",
      "Running method: supervised\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654a282e2ffc4433b4d585786b6313d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m all_available_datasets:\n\u001b[32m     37\u001b[39m     dataset = load_dataset_for_ccs(\n\u001b[32m     38\u001b[39m         dataset_name=dataset_name,\n\u001b[32m     39\u001b[39m         split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     40\u001b[39m         max_examples=\u001b[32m200\u001b[39m,\n\u001b[32m     41\u001b[39m         seed=\u001b[32m42\u001b[39m,\n\u001b[32m     42\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     all_results_dict[dataset_name] = \u001b[43mget_results_on_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_methods\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupervised\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mccs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mno_leakage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Option 1: Modern bar plot\u001b[39;00m\n\u001b[32m     55\u001b[39m fig1, ax1 = plot_auroc_comparison(all_results_dict, style=\u001b[33m'\u001b[39m\u001b[33mmodern\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:127\u001b[39m, in \u001b[36mget_results_on_dataset\u001b[39m\u001b[34m(dataset, model_name, layer_idx, test_size, seed, batch_size, run_methods, no_leakage)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsupervised-truth-probes/src/methods.py:518\u001b[39m, in \u001b[36m_run_supervised_method\u001b[39m\u001b[34m(train_pos_activations, train_neg_activations, train_labels, test_activations)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).parent\n",
    "\n",
    "sys.path.append(str(ROOT_DIR / 'src'))\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "sys.path.append(str(ROOT_DIR / 'promptsource'))\n",
    "sys.path.append(str(ROOT_DIR / 'promptsource' / 'promptsource'))\n",
    "\n",
    "from src.evals import *\n",
    "from src.methods import *\n",
    "from src.plotting import *\n",
    "\n",
    "all_available_datasets = [\n",
    "    \"boolq\",\n",
    "    # \"dbpedia_14\",\n",
    "    # \"imdb\",\n",
    "    # \"ag_news\",\n",
    "    # \"amazon_polarity\",\n",
    "    # \"piqa\",\n",
    "    #\"got_sp_en_trans\", # Empty for some reason\n",
    "    # \"rte\",\n",
    "    #\"got_larger_than\",\n",
    "    #\"got_cities\",\n",
    "    #\"copa\",\n",
    "]\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-70B\"\n",
    "\n",
    "all_results_dict = {}\n",
    "for dataset_name in all_available_datasets:\n",
    "    dataset = load_dataset_for_ccs(\n",
    "        dataset_name=dataset_name,\n",
    "        split=\"train\", \n",
    "        max_examples=200,\n",
    "        seed=42,\n",
    "    )\n",
    "    all_results_dict[dataset_name] = get_results_on_dataset(\n",
    "        dataset=dataset,\n",
    "        model_name=model_name,\n",
    "        layer_idx=32,\n",
    "        batch_size=8,\n",
    "        run_methods = [\"supervised\", \"ccs\"],\n",
    "        test_size=0.5,\n",
    "        no_leakage=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "# Option 1: Modern bar plot\n",
    "fig1, ax1 = plot_auroc_comparison(all_results_dict, style='modern')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mall_results_dict\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'all_results_dict' is not defined"
     ]
    }
   ],
   "source": [
    "all_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test repeng installation\n",
    "import repeng\n",
    "from repeng import extract_directions\n",
    "print(f\"Repeng version: {repeng.__version__}\")\n",
    "print(\"Repeng imported successfully!\")\n",
    "\n",
    "# Test basic functionality\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# You can test with a smaller model first\n",
    "test_model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "print(f\"\\nTesting with model: {test_model_name}\")\n",
    "\n",
    "# Example of extracting directions - adapt this to your use case\n",
    "# from repeng.extract import extract_directions, DatasetTemplate\n",
    "# You can explore the repeng API for your specific needs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a simple widget\n",
    "slider = widgets.IntSlider(value=50, min=0, max=100, description='Test:')\n",
    "button = widgets.Button(description='Click me!')\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        print(f\"Slider value is: {slider.value}\")\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(widgets.VBox([slider, button, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using repeng for representation engineering\n",
    "from repeng import ControlVector, ControlModel, DatasetTemplate\n",
    "\n",
    "# Create a dataset template for extracting directions\n",
    "# This is useful for finding truth/falsehood directions in model representations\n",
    "honesty_template = DatasetTemplate(\n",
    "    positive_examples=[\n",
    "        \"I need to be honest and tell the truth\",\n",
    "        \"Let me give you the accurate information\",\n",
    "        \"The facts are as follows\",\n",
    "    ],\n",
    "    negative_examples=[\n",
    "        \"I should lie about this\",\n",
    "        \"Let me make something up\",\n",
    "        \"The false information is\",\n",
    "    ],\n",
    "    suffix_list=[\"\"],  # Empty suffix for basic examples\n",
    ")\n",
    "\n",
    "# You can also work with your existing activations\n",
    "# Example of how to integrate with your current setup:\n",
    "def extract_truth_directions(model, tokenizer, dataset):\n",
    "    \"\"\"Extract truth/falsehood directions from model activations.\"\"\"\n",
    "    # This would integrate with your existing probing setup\n",
    "    pass\n",
    "\n",
    "# For more advanced usage, check repeng documentation:\n",
    "# - Extract control vectors for specific behaviors\n",
    "# - Apply control vectors to steer model outputs\n",
    "# - Analyze directions in representation space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference for repeng usage with your probing experiments\n",
    "\n",
    "# 1. Extract control vectors from paired examples\n",
    "from repeng.extract import extract_directions, ControlVector\n",
    "\n",
    "# 2. Use with your existing model and data\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 3. Create control vectors for truth/falsehood\n",
    "# truth_vector = extract_directions(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     positive_examples=[\"true statements\"],\n",
    "#     negative_examples=[\"false statements\"],\n",
    "#     layer_id=33,  # Same layer you're using\n",
    "# )\n",
    "\n",
    "# 4. Apply control vectors to influence model behavior\n",
    "# controlled_model = ControlModel(model, [truth_vector])\n",
    "\n",
    "# 5. Analyze directions in representation space\n",
    "# This complements your CCS and supervised probing methods!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
